{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/randy/Documents/GitHub/Twitch_Chat_Harassment/toxic_comment_classification/jigsaw-toxic-comment-classification-challenge/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 159571 items.\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset contains\", len(train), \"items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate the data itself and the target class labels into separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index = train['id']\n",
    "x_train = train['comment_text']\n",
    "y_train = train.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's also add a \"clean\" column to the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['clean'] = 1 - y_train.sum(axis=1) >= 1  \n",
    "# beginner note: if some kind of toxicity is detected, the sum across rows will yield one, \n",
    "# and the subtraction will give zero, and one otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinds, counts = zip(*y_train.sum(axis=0).items())\n",
    "# another beginner note: the sum operation yield a series, and a series behaves like a dictionary\n",
    "# as it has the items function that returns index-value tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "responsive": true,
        "showLink": false
       },
       "data": [
        {
         "type": "bar",
         "uid": "4f9a6067-cb0e-4f95-b356-8108cd127c4d",
         "x": [
          "toxic",
          "severe_toxic",
          "obscene",
          "threat",
          "insult",
          "identity_hate",
          "clean"
         ],
         "y": [
          15294,
          1595,
          8449,
          478,
          7877,
          1405,
          143346
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Class distribution in train set"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"3f9878e7-ce1c-448a-b201-acf60d6abac3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"3f9878e7-ce1c-448a-b201-acf60d6abac3\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '3f9878e7-ce1c-448a-b201-acf60d6abac3',\n",
       "                        [{\"type\": \"bar\", \"uid\": \"95eacfc7-90c0-4677-be86-4baf712971b4\", \"x\": [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\", \"clean\"], \"y\": [15294.0, 1595.0, 8449.0, 478.0, 7877.0, 1405.0, 143346.0]}],\n",
       "                        {\"title\": {\"text\": \"Class distribution in train set\"}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('3f9878e7-ce1c-448a-b201-acf60d6abac3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bars = go.Bar(\n",
    "        y=counts,\n",
    "        x=kinds,\n",
    "    )\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Class distribution in train set\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[bars], layout=layout)\n",
    "iplot(fig, filename='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we see is a very imbalanced dataset with most of the examples being clean. Let's print some comments from each category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from \"toxic\"\n",
      "You fucking guinea wop, greaseball, guido, new york piece of shit.  Go back to your bumfilled, AIDS infested, cesspool of a state.\n",
      "Get a psychatrist, moron. \n",
      "\n",
      "You 9/11 truthers make me sick. paranoid schizophrenics like yourself shouldn't be allowed to use a computer. I'd suggest that you stop lying on your userpage that your are in MENSA - clearly your not. Only retards think 9/11 was an inside job. Oh and take a bath. It's been months since you last took one.\n",
      "What... \n",
      "\n",
      "What are you doing? Don't fuck me. I fuck to Ryulong, not you.\n",
      "\n",
      "\n",
      "Sample from \"severe_toxic\"\n",
      "Why, hello, Mr.Fucking jackass cunt, remember me? I wasnt gone.Suck my fucking cock.\n",
      "\"I would like to extend a fat, robust FUCK YOU to the asshole who deleted my criticism of Schengen.  And you wonder why I continue to vandalize Wikipedia? Its because some fucking asshole from the Wiki community continually deletes whatever I post.  Yes I have used profanity, and yes I have often not followed protocols.  Yet when I have followed \"\"Wiki\"\" protocols, even kindly worded comments are promptly deleted by the assholes of Dickipedia.  To all of you at Wikipedia, I extend a fat and boisterous FUCK YOUfor deleting my comments -)\n",
      "\n",
      "\"\n",
      "NOT SET IN NEW YORK !!!! \n",
      "why when i deleted the Category Video games set in New York City some retardeds keep putting it back ? now for all the retards who think it should be back listen up-the game takes place in liberty city not new york !!!!!! just because liberty city is based on new york does not mean that the game is set in new york you fucking retards !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "\n",
      "Sample from \"obscene\"\n",
      "I'm very upset that you've done this to me and ur a big shithead !!!!! I think that ur probbly black bcuz ur stupid\n",
      "how big is ur cock \n",
      "\n",
      "i wanna suck u dry\n",
      "Irishguy delets other people shit. Cuz noone likes him\n",
      "\n",
      "\n",
      "Sample from \"threat\"\n",
      "You Are A Piece Of Shit \n",
      "\n",
      "How dare you deface the truth! You disgusting piece of slime, you vile wretch, you do not deserve life, I should take your pathetic heart out of your chest and watch its' last withering beats die out in my hand. NOOB. SCUM. \n",
      "\n",
      "When I am the supreme ruler of planet earth I will see to it that you are the first to be thrown into the furnace, I will heat the populace of my great cities with your ashes.\n",
      "\n",
      "D I E\n",
      "\n",
      "hehe\n",
      "Your death\n",
      "You shitty fucktard, I am going to cut your balls of and feed them to my dog. Then, I am going to slit your shitpoke throat you mother-fucking cunt! -Jay Barnabay\n",
      "I am going to shove a pineapple up your ass. \n",
      "\n",
      "You'll fucking need major surgery to pull that shit out!\n",
      "\n",
      "\n",
      "Sample from \"insult\"\n",
      "FUCK YOU\n",
      "This has nothing to do with a Jewish cabal or anti-semitism. It has to do with Orangemarlin being a jerk, an imposter and a sockpuppet.\n",
      "Fraggle81 ==\n",
      "I can just make new accounts every time I want to attack you. Proxy. Faggot.\n",
      "\n",
      "==\n",
      "\n",
      "\n",
      "Sample from \"identity_hate\"\n",
      "why'd you remove that \n",
      "\n",
      "u nlgga\n",
      "Christmas Is Where Family's Come Together To Celebrate Jesus's Birthday..!\n",
      "Y Is Called Christmas I Have No Idea But If You Ask What I Have To Say About It Is Fuck Him..!\n",
      "There's Also Jews..!\n",
      "We Need Holidays To Wear Everyone Can Celebrate Them Together..!\n",
      "If You Wanna Celebrate Jesus Then Go To Fuckin Church..!\n",
      "This Is How I Fell..!\n",
      "Donate You're Feelings To www.donate_feelings.com\n",
      "I too am a gay pedophile\n",
      "\n",
      "\n",
      "Sample from \"clean\"\n",
      "I think Andy Taylor was the best musician in Duran Duran, he was right to leave over not wanting to work with Timberland. John and Roger together are better, they are a very underated and tight rythm section. Nick is more of a sound designer than a musician, although he is a genius songwriter and the best songwriter in the band. I never really liked Notorious & I dont want your love, then I saw those songs live and now I love them, how weird is that?( )\n",
      "Terry Crews \n",
      "\n",
      "Terry Crews is in the video as the cop Y2J RKO\n",
      "Can you guys check Land Down Under for any content problems (date of release for example).  Farmbrough, 10:29 24 October 2008 (UTC).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for kind in y_train.columns:\n",
    "    print('Sample from \"{}\"'.format(kind))\n",
    "    x_kind = x_train[y_train[kind]==1].sample(3)\n",
    "    print(\"\\n\".join(x_kind))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These comments are abhorrant, which underlines the importance of the task. We can also see that they really need some normalization:\n",
    "1. We may consider lowercasing - this is a common operation, but we can see that there are a lot of CAPS in toxic comments, so this might turn out to be a useful feature.\n",
    "2. Also, there are excessive punctuation and whitespace characters. Whitespaces sure need trimming, while punctuation is very demonstrative of emotions, which are often present in the comments.\n",
    "3. Another thing is to use a lemmatizer to lower the dimensionality of our vector space (if we use bag of words representation). This will be the next thing to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text normalization\n",
    "We will use spaCy to lemmatize the text (i.e. convert every word into its dictionary form) and we will also load the list of English stopwords (words that appear commonly but do not really convey a lot of meaning, like \"the\" or \"at\") from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\", disable=['parser', 'tagger', 'ner'])\n",
    "stops = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(comment, lowercase, remove_stopwords):\n",
    "    if lowercase:\n",
    "        comment = comment.lower()\n",
    "    comment = nlp(comment)\n",
    "    lemmatized = list()\n",
    "    for word in comment:\n",
    "        lemma = word.lemma_.strip()\n",
    "        if lemma:\n",
    "            if not remove_stopwords or (remove_stopwords and lemma not in stops):\n",
    "                lemmatized.append(lemma)\n",
    "    return \" \".join(lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply our function to the texts of the comments to normalize them. Note that we can change flags like lowercase or remove_stopwords when we want to try different strategies later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lemmatized = x_train.apply(normalize, lowercase=True, remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"think keep get mix someone else . number good beyond western estimate , however . ' ' ' ' ' '\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_lemmatized.sample(1).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word frequency visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_counts = dict()\n",
    "\n",
    "for kind in y_train.columns:\n",
    "    word_counts[kind] = Counter()\n",
    "    comments = x_train_lemmatized[y_train[kind]==1]\n",
    "    for _, comment in comments.iteritems():\n",
    "        word_counts[kind].update(comment.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_words(kind, num_words=15):\n",
    "    words, counts = zip(*word_counts[kind].most_common(num_words)[::-1])\n",
    "    bars = go.Bar(\n",
    "        y=words,\n",
    "        x=counts,\n",
    "        orientation=\"h\"\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=\"Most common words of the class \\\"{}\\\"\".format(kind),\n",
    "        yaxis=dict(\n",
    "            ticklen=8  # to add some space between yaxis labels and the plot\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=[bars], layout=layout)\n",
    "    iplot(fig, filename='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "responsive": true,
        "showLink": false
       },
       "data": [
        {
         "orientation": "h",
         "type": "bar",
         "uid": "1cd9d0e2-489b-4f9e-a113-a815d984f124",
         "x": [
          523,
          561,
          602,
          704,
          836,
          884,
          934,
          980,
          1313,
          1321,
          1434,
          2141,
          2577,
          2810,
          3086
         ],
         "y": [
          "suck",
          "-PRON-",
          "?",
          "faggot",
          "-",
          "die",
          "gay",
          "\"",
          "jew",
          "fat",
          "fuck",
          ",",
          ".",
          "!",
          "nigger"
         ]
        }
       ],
       "layout": {
        "title": {
         "text": "Most common words of the class \"identity_hate\""
        },
        "yaxis": {
         "ticklen": 8
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"0c864b44-c1bf-4ee2-9868-7f9bd981e92b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"0c864b44-c1bf-4ee2-9868-7f9bd981e92b\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '0c864b44-c1bf-4ee2-9868-7f9bd981e92b',\n",
       "                        [{\"orientation\": \"h\", \"type\": \"bar\", \"uid\": \"fb52d48c-da7b-488d-bb2e-03c350dfb877\", \"x\": [523, 561, 602, 704, 836, 884, 934, 980, 1313, 1321, 1434, 2141, 2577, 2810, 3086], \"y\": [\"suck\", \"-PRON-\", \"?\", \"faggot\", \"-\", \"die\", \"gay\", \"\\\"\", \"jew\", \"fat\", \"fuck\", \",\", \".\", \"!\", \"nigger\"]}],\n",
       "                        {\"title\": {\"text\": \"Most common words of the class \\\"identity_hate\\\"\"}, \"yaxis\": {\"ticklen\": 8}},\n",
       "                        {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('0c864b44-c1bf-4ee2-9868-7f9bd981e92b');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# most_common_words(\"toxic\")\n",
    "# most_common_words(\"severe_toxic\")\n",
    "# most_common_words(\"obscene\")\n",
    "# most_common_words(\"threat\")\n",
    "# most_common_words(\"insult\")\n",
    "most_common_words(\"identity_hate\")\n",
    "# most_common_words(\"clean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
