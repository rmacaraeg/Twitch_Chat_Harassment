{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from scipy.sparse import hstack\n",
    "from scipy.special import logit, expit\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('/Users/randy/Documents/GitHub/Twitch_Chat_Harassment/toxic_comment_classification/jigsaw-toxic-comment-classification-challenge/cleaned_train.csv').fillna(' ')\n",
    "test = pd.read_csv('/Users/randy/Documents/GitHub/Twitch_Chat_Harassment/toxic_comment_classification/jigsaw-toxic-comment-classification-challenge/cleaned_test.csv').fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove non-ascii characters\n",
    "def remove_non_ascii(text):\n",
    "    text  = \"\".join([char for char in text if char in string.printable])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "train['comment_text'] = train['comment_text'].apply(lambda x: remove_non_ascii(x))\n",
    "test['comment_text'] = test['comment_text'].apply(lambda x: remove_non_ascii(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences_train = train['comment_text']\n",
    "list_sentences_test = test['comment_text']\n",
    "all_text = pd.concat([list_sentences_train, list_sentences_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = list_sentences_train.loc[train['toxic'] == 1]\n",
    "severe_toxic = list_sentences_train.loc[train['toxic'] == 1]\n",
    "obscene = list_sentences_train.loc[train['toxic'] == 1]\n",
    "threat = list_sentences_train.loc[train['toxic'] == 1]\n",
    "insult = list_sentences_train.loc[train['toxic'] == 1]\n",
    "identity_hate = list_sentences_train.loc[train['toxic'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cl_path = '/Users/randy/Documents/GitHub/Twitch_Chat_Harassment/toxic_comment_classification/jigsaw-toxic-comment-classification-challenge/cleanwords.txt'\n",
    "clean_word_dict = {}\n",
    "with open(cl_path, 'r', encoding='utf-8') as cl:\n",
    "    for line in cl:\n",
    "        line = line.strip('\\n')\n",
    "        typo, correct = line.split(',')\n",
    "        clean_word_dict[typo] = correct\n",
    "\n",
    "def clean_word(text):\n",
    "    replace_numbers = re.compile(r'\\d+', re.IGNORECASE)\n",
    "    special_character_removal = re.compile(r'[^a-z\\d ]', re.IGNORECASE)\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*)\", \"\", text)\n",
    "    text = re.sub(r\"(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(\\.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}\", \"\", text)\n",
    "\n",
    "    for typo, correct in clean_word_dict.items():\n",
    "        text = re.sub(typo, \" \" + correct + \" \", text)\n",
    "\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"iâ€™m\", \"i am\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    text = replace_numbers.sub('', text)\n",
    "    return text\n",
    "\n",
    "train_text = []\n",
    "test_text = []\n",
    "toxic_text = []\n",
    "severe_toxic_text = []\n",
    "obscene_text = []\n",
    "threat_text = []\n",
    "insult_text = []\n",
    "identity_hate_text = []\n",
    "\n",
    "for text in list_sentences_train:\n",
    "    train_text.append(clean_word(text))\n",
    "    \n",
    "for text in list_sentences_test:\n",
    "    test_text.append(clean_word(text))\n",
    "    \n",
    "for text in toxic:\n",
    "    toxic_text.append(clean_word(text))\n",
    "\n",
    "for text in severe_toxic_text:\n",
    "    severe_toxic_text.append(clean_word(text))\n",
    "\n",
    "for text in obscene_text:\n",
    "    obscene_text.append(clean_word(text))\n",
    "\n",
    "for text in threat:\n",
    "    threat_text.append(clean_word(text))\n",
    "\n",
    "for text in insult:\n",
    "    insult_text.append(clean_word(text))\n",
    "\n",
    "for text in identity_hate:\n",
    "    identity_hate_text.append(clean_word(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for EFC\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=30000)\n",
    "word_vectorizer.fit(all_text)\n",
    "\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('explanation', 9455)\n",
      "('edits', 8445)\n",
      "('username', 28238)\n",
      "('hardcore', 11961)\n",
      "('metallica', 16749)\n",
      "('fan', 9724)\n",
      "('reverted', 22598)\n",
      "('vandalisms', 28368)\n",
      "('just', 14495)\n",
      "('closure', 4861)\n"
     ]
    }
   ],
   "source": [
    "#ties the TF-IDF keys to the values\n",
    "for item in zip(list(word_vectorizer.vocabulary_.keys())[:10],list(word_vectorizer.vocabulary_.values())[:10]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for logit\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=30000)\n",
    "char_vectorizer.fit(all_text)\n",
    "\n",
    "train_char_features = char_vectorizer.transform(train_text)\n",
    "test_char_features = char_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=30000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents='unicode', sublinear_tf=True,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vectorizer.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply CountVectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for logit\n",
    "count_vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=30000)\n",
    "count_vec_fit = count_vectorizer.fit(all_text)\n",
    "\n",
    "train_count_features = count_vectorizer.transform(train_text)\n",
    "test_count_features = count_vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count_features.toarray().sum(axis=0)\n",
    "count_df = pd.DataFrame(count_vec_fit.get_feature_names())\n",
    "count_df['counts'] = train_count_features.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizers (for each individual topic/feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toxic\n",
    "toxic_vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=30000)\n",
    "toxic_vec_fit = toxic_vectorizer.fit(all_text)\n",
    "\n",
    "toxic_count_features = toxic_vectorizer.transform(toxic_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_count_df = pd.DataFrame(toxic_vec_fit.get_feature_names())\n",
    "toxic_count_df['counts'] = toxic_count_features.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#severe_toxic\n",
    "severe_toxic_vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=30000)\n",
    "severe_toxic_vec_fit = severe_toxic_vectorizer.fit(all_text)\n",
    "\n",
    "severe_toxic_count_features = severe_toxic_vectorizer.transform(severe_toxic_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severe_toxic_count_df = pd.DataFrame(severe_toxic_vec_fit.get_feature_names())\n",
    "severe_toxic_count_df['counts'] = severe_toxic_count_features.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obscene\n",
    "obscene_vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=30000)\n",
    "obscene_vec_fit = obscene_vectorizer.fit(all_text)\n",
    "\n",
    "obscene_count_features = obscene_vectorizer.transform(obscene_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obscene_count_df = pd.DataFrame(obscene_vec_fit.get_feature_names())\n",
    "obscene_count_df['counts'] = obscene_count_features.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threat\n",
    "threat_vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=30000)\n",
    "threat_vec_fit = threat_vectorizer.fit(all_text)\n",
    "\n",
    "threat_count_features = threat_vectorizer.transform(threat_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_count_df = pd.DataFrame(threat_vec_fit.get_feature_names())\n",
    "threat_count_df['counts'] = threat_count_features.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insult\n",
    "insult_vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=30000)\n",
    "insult_vec_fit = insult_vectorizer.fit(all_text)\n",
    "\n",
    "insult_count_features = insult_vectorizer.transform(insult_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insult_count_df = pd.DataFrame(insult_vec_fit.get_feature_names())\n",
    "insult_count_df['counts'] = insult_count_features.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identity_hate\n",
    "identity_hate_vectorizer = CountVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    stop_words='english',\n",
    "    max_features=30000)\n",
    "identity_hate_vec_fit = identity_hate_vectorizer.fit(all_text)\n",
    "\n",
    "identity_hate_count_features = identity_hate_vectorizer.transform(identity_hate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_hate_count_df = pd.DataFrame(identity_hate_vec_fit.get_feature_names())\n",
    "identity_hate_count_df['counts'] = identity_hate_count_features.toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_of_toxic_category(category_string):\n",
    "    '''category string must match train dataframe column name exactly ''' \n",
    "    filtered_sentences = list_sentences_train.loc[train[category_string] == 1]\n",
    "    category_vectorizer = CountVectorizer(\n",
    "        strip_accents='unicode',\n",
    "        analyzer='word',\n",
    "        ngram_range=(1, 1),\n",
    "        stop_words='english',\n",
    "        max_features=30000)\n",
    "    category_vec_fit = category_vectorizer.fit(filtered_sentences)\n",
    "\n",
    "    category_count_features = category_vectorizer.transform(filtered_sentences)\n",
    "    category_count_df = pd.DataFrame(category_vec_fit.get_feature_names())\n",
    "    category_count_df['counts'] = category_count_features.toarray().sum(axis=0)\n",
    "    category_count_df.rename(columns = {0: 'word'})\n",
    "    return category_count_df, filtered_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_specific_vocab_dict = dict()\n",
    "class_specific_sentences = dict()\n",
    "for class_name in class_names:\n",
    "    class_specific_vocab_dict[class_name] = \\\n",
    "        create_df_of_toxic_category(class_name)[0].sort_values('counts', ascending = False)\n",
    "    class_specific_sentences[class_name] =\\\n",
    "            create_df_of_toxic_category(class_name)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_string = ''\n",
    "for line in class_specific_sentences['toxic']:\n",
    "    toxic_string+=' ' + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__',\n",
       " '___',\n",
       " '____',\n",
       " '_____',\n",
       " '______',\n",
       " '__toc__',\n",
       " '_id',\n",
       " '_l',\n",
       " '_noticeboard',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaa',\n",
       " 'aad',\n",
       " 'aah',\n",
       " 'aahahahahahahjaahahahahahahaahh',\n",
       " 'aaliyah',\n",
       " 'aan',\n",
       " 'aap',\n",
       " 'aardvark',\n",
       " 'aaron',\n",
       " 'aas',\n",
       " 'aave',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'aback',\n",
       " 'abad',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abba',\n",
       " 'abbas',\n",
       " 'abbey',\n",
       " 'abbot',\n",
       " 'abbott',\n",
       " 'abbrev',\n",
       " 'abbreviate',\n",
       " 'abbreviated',\n",
       " 'abbreviation',\n",
       " 'abbreviations',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abd',\n",
       " 'abdel',\n",
       " 'abdelkader',\n",
       " 'abducted',\n",
       " 'abduction',\n",
       " 'abdul',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'abeed',\n",
       " 'abel',\n",
       " 'aber',\n",
       " 'abf',\n",
       " 'abhira',\n",
       " 'abhiras',\n",
       " 'abhishek',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abi',\n",
       " 'abide',\n",
       " 'abiding',\n",
       " 'abigail',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abiogenesis',\n",
       " 'abit',\n",
       " 'abject',\n",
       " 'abkhazia',\n",
       " 'able',\n",
       " 'abnormal',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abolition',\n",
       " 'abolitionist',\n",
       " 'abomination',\n",
       " 'aboriginal',\n",
       " 'aborigines',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'aboutus',\n",
       " 'abraham',\n",
       " 'abrahamic',\n",
       " 'abramoff',\n",
       " 'abrams',\n",
       " 'abrasive',\n",
       " 'abridged',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutly',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorption',\n",
       " 'abstain',\n",
       " 'abstaining',\n",
       " 'abstimmungsgegner',\n",
       " 'abstinence',\n",
       " 'abstract',\n",
       " 'abstraction',\n",
       " 'abstracts',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abt',\n",
       " 'abtract',\n",
       " 'abu',\n",
       " 'abuja',\n",
       " 'abujihad',\n",
       " 'abul',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abut',\n",
       " 'abysmal',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'aca',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academical',\n",
       " 'academically',\n",
       " 'academics',\n",
       " 'academies',\n",
       " 'academy',\n",
       " 'acalamari',\n",
       " 'acc',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerating',\n",
       " 'acceleration',\n",
       " 'accelerations',\n",
       " 'accelerator',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptability',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessable',\n",
       " 'accessdate',\n",
       " 'accessed',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accession',\n",
       " 'accessories',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accomodate',\n",
       " 'accompanied',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'accorded',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accords',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accreditation',\n",
       " 'accredited',\n",
       " 'accross',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulating',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accusatory',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accusers',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accussed',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'aces',\n",
       " 'ach',\n",
       " 'acharya',\n",
       " 'acheived',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'acid',\n",
       " 'acids',\n",
       " 'acim',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'ackoz',\n",
       " 'aclu',\n",
       " 'acm',\n",
       " 'acn',\n",
       " 'aco',\n",
       " 'acording',\n",
       " 'acorn',\n",
       " 'acosta',\n",
       " 'acount',\n",
       " 'acoustic',\n",
       " 'acquaint',\n",
       " 'acquaintance',\n",
       " 'acquainted',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acquitted',\n",
       " 'acr',\n",
       " 'acre',\n",
       " 'acreees',\n",
       " 'acres',\n",
       " 'acronym',\n",
       " 'acronyms',\n",
       " 'acroterion',\n",
       " 'acs',\n",
       " 'act',\n",
       " 'acta',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activation',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'acu',\n",
       " 'acupuncture',\n",
       " 'acutally',\n",
       " 'acute',\n",
       " 'acw',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adalah',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adams',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adapting',\n",
       " 'adaptive',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addison',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'addy',\n",
       " 'adelaide',\n",
       " 'adele',\n",
       " 'adept',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adhd',\n",
       " 'adhere',\n",
       " 'adhered',\n",
       " 'adherence',\n",
       " 'adherent',\n",
       " 'adherents',\n",
       " 'adheres',\n",
       " 'adhering',\n",
       " 'adi',\n",
       " 'adidas',\n",
       " 'adige',\n",
       " 'adil',\n",
       " 'adios',\n",
       " 'adj',\n",
       " 'adjacent',\n",
       " 'adjectival',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjoining',\n",
       " 'adjunct',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adl',\n",
       " 'adler',\n",
       " 'adm',\n",
       " 'admi',\n",
       " 'admin',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administers',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admins',\n",
       " 'adminship',\n",
       " 'adminstrator',\n",
       " 'adminstrators',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiral',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admissible',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admittance',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admixture',\n",
       " 'admonished',\n",
       " 'adn',\n",
       " 'adnan',\n",
       " 'ado',\n",
       " 'adobe',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adolf',\n",
       " 'adolph',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adoptee',\n",
       " 'adopter',\n",
       " 'adopters',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adorned',\n",
       " 'adrenaline',\n",
       " 'adress',\n",
       " 'adressed',\n",
       " 'adresses',\n",
       " 'adrian',\n",
       " 'adriatic',\n",
       " 'adrift',\n",
       " 'ads',\n",
       " 'adsydfiusagjfasfsduyaidfasgiudf',\n",
       " 'adult',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'adv',\n",
       " 'advaita',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantageous',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adventist',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adverb',\n",
       " 'adversarial',\n",
       " 'adversaries',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversely',\n",
       " 'advert',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertiser',\n",
       " 'advertisers',\n",
       " 'advertises',\n",
       " 'advertising',\n",
       " 'advertisment',\n",
       " 'adverts',\n",
       " 'advice',\n",
       " 'advices',\n",
       " 'advisable',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advisers',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advisory',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'advocates',\n",
       " 'advocating',\n",
       " 'ae',\n",
       " 'aegean',\n",
       " 'aeon',\n",
       " 'aerial',\n",
       " 'aero',\n",
       " 'aerodynamics',\n",
       " 'aeropagitica',\n",
       " 'aeroplane',\n",
       " 'aerosol',\n",
       " 'aerospace',\n",
       " 'aes',\n",
       " 'aesop',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'aether',\n",
       " 'aewaa',\n",
       " 'af',\n",
       " 'afa',\n",
       " 'afaict',\n",
       " 'afaik',\n",
       " 'afar',\n",
       " 'afc',\n",
       " 'afd',\n",
       " 'afds',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affects',\n",
       " 'affidavit',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affiliates',\n",
       " 'affiliation',\n",
       " 'affiliations',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmative',\n",
       " 'affirmed',\n",
       " 'affirming',\n",
       " 'affirms',\n",
       " 'affix',\n",
       " 'afflicted',\n",
       " 'affluent',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affront',\n",
       " 'afghan',\n",
       " 'afghani',\n",
       " 'afghanistan',\n",
       " 'afghans',\n",
       " 'afghooni',\n",
       " 'afi',\n",
       " 'afic',\n",
       " 'afl',\n",
       " 'aforementioned',\n",
       " 'afoul',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africans',\n",
       " 'afrika',\n",
       " 'afrinic',\n",
       " 'afro',\n",
       " 'afrocentric',\n",
       " 'afrocentrism',\n",
       " 'aft',\n",
       " 'afterall',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'ag',\n",
       " 'aga',\n",
       " 'agains',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'agf',\n",
       " 'aggie',\n",
       " 'aggiebean',\n",
       " 'aggrandizing',\n",
       " 'aggravated',\n",
       " 'aggravating',\n",
       " 'aggregate',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggressor',\n",
       " 'aggressors',\n",
       " 'aggrieved',\n",
       " 'agian',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'agitation',\n",
       " 'agk',\n",
       " 'agnes',\n",
       " 'agnostic',\n",
       " 'agnosticism',\n",
       " 'agnostics',\n",
       " 'ago',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agressive',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'aguante',\n",
       " 'aguilera',\n",
       " 'agw',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahahahahahahahaha',\n",
       " 'ahahahahahahahahahahahahahahahahahahaha',\n",
       " 'ahbash',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhhhhhhhhha',\n",
       " 'ahir',\n",
       " 'ahistorical',\n",
       " 'ahle',\n",
       " 'ahmad',\n",
       " 'ahmadinejad',\n",
       " 'ahmadiyya',\n",
       " 'ahmed',\n",
       " 'ahole',\n",
       " 'ahot',\n",
       " 'ahoy',\n",
       " 'ahs',\n",
       " 'ahunt',\n",
       " 'ahve',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aide',\n",
       " 'aided',\n",
       " 'aiden',\n",
       " 'aiding',\n",
       " 'aids',\n",
       " 'aidsaids',\n",
       " 'aig',\n",
       " 'aikido',\n",
       " 'aillrin',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'ainu',\n",
       " 'aipac',\n",
       " 'air',\n",
       " 'airbender',\n",
       " 'airborne',\n",
       " 'airbus',\n",
       " 'aircraft',\n",
       " 'airdate',\n",
       " 'airdates',\n",
       " 'aired',\n",
       " 'aires',\n",
       " 'airforce',\n",
       " 'airing',\n",
       " 'airline',\n",
       " 'airliner',\n",
       " 'airliners',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airplay',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airs',\n",
       " 'airship',\n",
       " 'airways',\n",
       " 'ait',\n",
       " 'aiv',\n",
       " 'aj',\n",
       " 'ajaltoun',\n",
       " 'ajax',\n",
       " 'ajay',\n",
       " 'ajith',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akan',\n",
       " 'akbar',\n",
       " 'akc',\n",
       " 'aki',\n",
       " 'akin',\n",
       " 'akins',\n",
       " 'akira',\n",
       " 'akkadian',\n",
       " 'ako',\n",
       " 'akon',\n",
       " 'aku',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'aladdin',\n",
       " 'alain',\n",
       " 'alamo',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alas',\n",
       " 'alasdair',\n",
       " 'alaska',\n",
       " 'alaskan',\n",
       " 'alba',\n",
       " 'albania',\n",
       " 'albanian',\n",
       " 'albanians',\n",
       " 'albany',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'alberto',\n",
       " 'albino',\n",
       " 'albion',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'albuquerque',\n",
       " 'alchemist',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alcoholics',\n",
       " 'alcoholism',\n",
       " 'alden',\n",
       " 'aldux',\n",
       " 'ale',\n",
       " 'alec',\n",
       " 'aleem',\n",
       " 'alejandro',\n",
       " 'aleppo',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alerting',\n",
       " 'alerts',\n",
       " 'alessandro',\n",
       " 'alex',\n",
       " 'alexa',\n",
       " 'alexander',\n",
       " 'alexandra',\n",
       " 'alexandria',\n",
       " 'alexandrovich',\n",
       " 'alexikoua',\n",
       " 'alexis',\n",
       " 'alf',\n",
       " 'alfa',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'algae',\n",
       " 'algebra',\n",
       " 'algebraic',\n",
       " 'algeria',\n",
       " 'algerian',\n",
       " 'algo',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'algrie',\n",
       " 'ali',\n",
       " 'alia',\n",
       " 'alias',\n",
       " 'aliases',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'aliens',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alison',\n",
       " 'alistair',\n",
       " 'alive',\n",
       " 'alkaline',\n",
       " 'alla',\n",
       " 'allah',\n",
       " 'allahu',\n",
       " 'allan',\n",
       " 'alle',\n",
       " 'alledged',\n",
       " 'allegation',\n",
       " 'allegations',\n",
       " 'allege',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'alleges',\n",
       " 'allegiance',\n",
       " 'alleging',\n",
       " 'allegory',\n",
       " 'allele',\n",
       " 'alleles',\n",
       " 'allemande',\n",
       " 'allen',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'alles',\n",
       " 'alleviate',\n",
       " 'alley',\n",
       " 'alliance',\n",
       " 'alliances',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'allison',\n",
       " 'alll',\n",
       " 'allmusic',\n",
       " 'allocated',\n",
       " 'allocation',\n",
       " 'allot',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alloy',\n",
       " 'allready',\n",
       " 'allright',\n",
       " 'alls',\n",
       " 'allude',\n",
       " 'alluded',\n",
       " 'alludes',\n",
       " 'alluding',\n",
       " 'allumungi',\n",
       " 'allusion',\n",
       " 'allusions',\n",
       " 'allways',\n",
       " 'ally',\n",
       " 'alma',\n",
       " 'almanac',\n",
       " 'almighty',\n",
       " 'alo',\n",
       " 'alongside',\n",
       " 'alonso',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alp',\n",
       " 'alpaugh',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alphabetic',\n",
       " 'alphabetical',\n",
       " 'alphabetically',\n",
       " 'alphabetized',\n",
       " 'alphabets',\n",
       " 'alphonse',\n",
       " 'alpine',\n",
       " 'alps',\n",
       " 'alr',\n",
       " 'alredy',\n",
       " 'alright',\n",
       " 'als',\n",
       " 'alstair',\n",
       " 'alstom',\n",
       " 'alt',\n",
       " 'alta',\n",
       " 'altaic',\n",
       " 'altar',\n",
       " 'altenmann',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'alterations',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternately',\n",
       " 'alternates',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'alters',\n",
       " 'altetendekrabbe',\n",
       " 'altho',\n",
       " 'altitude',\n",
       " 'alto',\n",
       " 'altogether',\n",
       " 'altruistic',\n",
       " 'alum',\n",
       " 'aluminium',\n",
       " 'aluminum',\n",
       " 'alumni',\n",
       " 'alumnus',\n",
       " 'alums',\n",
       " 'alun',\n",
       " 'alva',\n",
       " 'alvarez',\n",
       " 'alveolar',\n",
       " 'alves',\n",
       " 'alvin',\n",
       " 'alzheimer',\n",
       " 'ama',\n",
       " 'amalgamation',\n",
       " 'amalthea',\n",
       " 'amanda',\n",
       " 'amar',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurs',\n",
       " 'amaury',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'amb',\n",
       " 'ambassador',\n",
       " 'ambassadors',\n",
       " 'ambedkar',\n",
       " 'amber',\n",
       " 'ambient',\n",
       " 'ambiguities',\n",
       " 'ambiguity',\n",
       " 'ambiguous',\n",
       " 'ambiguously',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambitious',\n",
       " 'ambivalent',\n",
       " 'ambrose',\n",
       " 'ambulance',\n",
       " 'ambush',\n",
       " 'amc',\n",
       " 'amd',\n",
       " 'ame',\n",
       " 'amelia',\n",
       " 'amen',\n",
       " 'amenable',\n",
       " 'amend',\n",
       " 'amended',\n",
       " 'amending',\n",
       " 'amendment',\n",
       " 'amendments',\n",
       " 'amends',\n",
       " 'ameno',\n",
       " 'amer',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanism',\n",
       " 'americans',\n",
       " 'americas',\n",
       " 'americorps',\n",
       " 'amerika',\n",
       " 'amerindian',\n",
       " 'ames',\n",
       " 'amg',\n",
       " 'ami',\n",
       " 'amib',\n",
       " 'amicable',\n",
       " 'amicably',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amiga',\n",
       " 'amigo',\n",
       " 'amin',\n",
       " 'amino',\n",
       " 'amir',\n",
       " 'amirite',\n",
       " 'amish',\n",
       " 'amiss',\n",
       " 'amit',\n",
       " 'ammendment',\n",
       " 'ammo',\n",
       " 'ammonia',\n",
       " 'ammount',\n",
       " 'ammunition',\n",
       " 'amnesty',\n",
       " 'amok',\n",
       " 'amon',\n",
       " 'amor',\n",
       " 'amorphous',\n",
       " 'amortias',\n",
       " 'amos',\n",
       " 'amounted',\n",
       " 'amounting',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'amphetamine',\n",
       " 'amphibious',\n",
       " 'ample',\n",
       " 'amplitude',\n",
       " 'amply',\n",
       " 'ams',\n",
       " 'amsterdam',\n",
       " 'amtrak',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10704"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_vectorizer.transform([toxic_string]).toarray()[0] == word_vectorizer.transform([toxic_string]).toarray().max()).index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fucksex'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer.get_feature_names()[10704]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "toxic_sentences_transformed = word_vectorizer.transform(class_specific_sentences['toxic']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_sentences_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "743.4650972457656"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_sentences_transformed.sum(axis=0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>nigger</td>\n",
       "      <td>2969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>fat</td>\n",
       "      <td>1322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>jew</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>gay</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>fuck</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  counts\n",
       "4226  nigger    2969\n",
       "2225     fat    1322\n",
       "3328     jew    1315\n",
       "2535     gay     918\n",
       "2443    fuck     880"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_specific_vocab_dict['identity_hate'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "toxic_df = create_df_of_toxic_category('toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3781092c6b80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoxic_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'counts'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "toxic_df.sort_values('counts',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'rename'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-598fead97e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoxic_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'word'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'rename'"
     ]
    }
   ],
   "source": [
    "toxic_df.rename(columns = {0: 'word'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TfidfVectorizer.transform of TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=30000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents='unicode', sublinear_tf=True,\n",
       "        token_pattern='\\\\w{1,}', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer.transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_break, X_test, y_break, y_test = train_test_split(no_fraud_result, result_df['isFraud'], \\\n",
    "                                                    test_size=0.2, stratify=result_df['isFraud'],\n",
    "                                                    random_state=42)\n",
    "#random_state generates a set kind of deck for each random state. 41 will always be the same kind of split\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_break, y_break, \\\n",
    "#                                                     test_size=0.25, stratify=y_break,\n",
    "#                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "5         0\n",
       "6         1\n",
       "7         0\n",
       "8         0\n",
       "9         0\n",
       "10        0\n",
       "11        0\n",
       "12        1\n",
       "13        0\n",
       "14        0\n",
       "15        0\n",
       "16        1\n",
       "17        0\n",
       "18        0\n",
       "19        0\n",
       "20        0\n",
       "21        0\n",
       "22        0\n",
       "23        0\n",
       "24        0\n",
       "25        0\n",
       "26        0\n",
       "27        0\n",
       "28        0\n",
       "29        0\n",
       "         ..\n",
       "159541    1\n",
       "159542    0\n",
       "159543    0\n",
       "159544    0\n",
       "159545    0\n",
       "159546    1\n",
       "159547    0\n",
       "159548    0\n",
       "159549    0\n",
       "159550    0\n",
       "159551    0\n",
       "159552    0\n",
       "159553    0\n",
       "159554    1\n",
       "159555    0\n",
       "159556    0\n",
       "159557    0\n",
       "159558    0\n",
       "159559    0\n",
       "159560    0\n",
       "159561    0\n",
       "159562    0\n",
       "159563    0\n",
       "159564    0\n",
       "159565    0\n",
       "159566    0\n",
       "159567    0\n",
       "159568    0\n",
       "159569    0\n",
       "159570    0\n",
       "Name: toxic, Length: 159571, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x30000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3645794 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is kept for heroku purposes\n",
    "train_features = train_word_features\n",
    "test_features = test_word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.971021009852267,\n",
       " 0.9857997393949715,\n",
       " 0.9858932794065138,\n",
       " 0.9834772645391503,\n",
       " 0.9769462290631367,\n",
       " 0.9748322041596338]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on toxic set: 0.96202\n",
      "CV score for class toxic is 0.9702816821525904\n",
      "Accuracy of logistic regression classifier on severe_toxic set: 0.99104\n",
      "CV score for class severe_toxic is 0.9857997691866469\n",
      "Accuracy of logistic regression classifier on obscene set: 0.98003\n",
      "CV score for class obscene is 0.9859225536450635\n",
      "Accuracy of logistic regression classifier on threat set: 0.99729\n",
      "CV score for class threat is 0.9823473609706234\n",
      "Accuracy of logistic regression classifier on insult set: 0.97317\n",
      "CV score for class insult is 0.9769462152486753\n",
      "Accuracy of logistic regression classifier on identity_hate set: 0.99240\n",
      "CV score for class identity_hate is 0.9749884284130234\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "log_predictions = {}\n",
    "log_predictions = {'id': test['id']}\n",
    "log_models = {}\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    log_classifier = LogisticRegression(solver='sag')\n",
    "    log_classifier.fit(train_features, train_target)\n",
    "    \n",
    "    print('Accuracy of logistic regression classifier on {} set: {:.5f}'.format(class_name,log_classifier.score(train_features, train_target)))\n",
    "    \n",
    "    cv_loss = np.mean(cross_val_score(log_classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    losses.append(cv_loss)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_loss))\n",
    "    \n",
    "    log_models[class_name] = log_classifier\n",
    "    log_predictions[class_name] = log_classifier.predict_proba(test_features)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on toxic set: 0.98966\n",
      "CV score for class toxic is 0.971021009852267\n",
      "Accuracy of logistic regression classifier on severe_toxic set: 0.99242\n",
      "CV score for class severe_toxic is 0.9857997393949715\n",
      "Accuracy of logistic regression classifier on obscene set: 0.99357\n",
      "CV score for class obscene is 0.9858932794065138\n",
      "Accuracy of logistic regression classifier on threat set: 0.99838\n",
      "CV score for class threat is 0.9834772645391503\n",
      "Accuracy of logistic regression classifier on insult set: 0.98785\n",
      "CV score for class insult is 0.9769462290631367\n",
      "Accuracy of logistic regression classifier on identity_hate set: 0.99028\n",
      "CV score for class identity_hate is 0.9748322041596338\n"
     ]
    }
   ],
   "source": [
    "# Run CV with 5 folds (logit)\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "losses = []\n",
    "log_predictions = {}\n",
    "log_predictions = {'id': test['id']}\n",
    "log_models = {}\n",
    "penalty = ['l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "param_grid = dict(C=C, penalty=penalty)\n",
    "\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    logistic = LogisticRegression(solver='sag')\n",
    "    logistic_grid = GridSearchCV(logistic, param_grid, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    logistic_grid.fit(train_features, train_target)\n",
    "#     log_classifier = LogisticRegression(solver='sag')\n",
    "#     log_classifier.fit(train_features, train_target)\n",
    "    \n",
    "    print('Accuracy of logistic regression classifier on {} set: {:.5f}'.format(class_name,logistic_grid.score(train_features, train_target)))\n",
    "    \n",
    "    cv_loss = np.mean(cross_val_score(logistic_grid, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    losses.append(cv_loss)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_loss))\n",
    "    \n",
    "    log_models[class_name] = log_classifier\n",
    "    log_predictions[class_name] = logistic_grid.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99833293, 0.00356479, 0.02498918, ..., 0.00510029, 0.01680948,\n",
       "       0.9965585 ])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_predictions['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_models['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() of unsized object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-c50414e65829>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# calculate roc curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'toxic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot no skill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \"\"\"\n\u001b[1;32m    617\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 618\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# Check to make sure y_true is valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    396\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# Invalid inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     if y.ndim > 2 or (y.dtype == object and len(y) and\n\u001b[0m\u001b[1;32m    271\u001b[0m                       not isinstance(y.flat[0], string_types)):\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'unknown'\u001b[0m  \u001b[0;31m# [[[1, 2]]] or [obj_1] and not [\"label_1\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of unsized object"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# split into train/test sets\n",
    "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "# fit a model\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(trainX, trainy)\n",
    "# predict probabilities\n",
    "probs = model.predict_proba(testX)\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = probs[:, 1]\n",
    "# calculate AUC\n",
    "auc = roc_auc_score(testy, probs)\n",
    "print('AUC: %.3f' % auc)\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(testy, probs)\n",
    "# plot no skill\n",
    "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(fpr, tpr, marker='.')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gnb_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-83016bdf7ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_list = [logistic_grid.best_estimator_, \n\u001b[1;32m      2\u001b[0m \u001b[0;31m#               svm_grid.best_estimator_,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m               \u001b[0mgnb_best\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#               rf_random.best_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#               knn_grid.best_estimator_,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gnb_best' is not defined"
     ]
    }
   ],
   "source": [
    "model_list = [log_models['toxic'],\n",
    "              log_models['severe_toxic'],\n",
    "              log_models['obscene'],\n",
    "              log_models['threat'],\n",
    "              log_models['insult'],\n",
    "              log_models['identity_hate']\n",
    "#               logistic_grid.best_estimator_, \n",
    "#               svm_grid.best_estimator_, \n",
    "#               gnb_best,\n",
    "#               rf_random.best_estimator_\n",
    "#               knn_grid.best_estimator_,\n",
    "#               CV_rfc.best_estimator_,\n",
    "#              dc\n",
    "             ]\n",
    "\n",
    "model_name = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'] \n",
    " \n",
    "# Plot ROC curve for all my models\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "for i, model in enumerate(model_list):\n",
    "    y_pred = list(model.predict_proba(X_val)[:,1])\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_val, y_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label = (model_name[i] + ' AUC = %0.4f' % roc_auc),linewidth=1.0)\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle the models\n",
    "# Save Model as a pickle Using joblib\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "  \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(log_models, 'Logistic_Regression_models.p')\n",
    "pickle.dump(train_char_features, open(\"train_char_features_vectorizer.p\", \"wb\"))\n",
    "pickle.dump(test_char_features, open(\"test_char_features_vectorizer.p\", \"wb\"))\n",
    "pickle.dump(word_vectorizer.fit(all_text), open(\"log_word_vectorizer.p\", \"wb\"))\n",
    "\n",
    "  \n",
    "# Load the model from the file \n",
    "# pickled_models = joblib.load('models.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "losses = []\n",
    "etc_predictions = {'id': test['id']}\n",
    "etc_models = {}\n",
    "for class_name in class_names:\n",
    "    train_target = train[class_name]\n",
    "    etc_classifier = ExtraTreesClassifier(n_estimators=30)\n",
    "    \n",
    "    cv_loss = np.mean(cross_val_score(etc_classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "    losses.append(cv_loss)\n",
    "    print('CV score for class {} is {}'.format(class_name, cv_loss))\n",
    "    \n",
    "    etc_classifier.fit(train_features, train_target)\n",
    "    etc_models[class_name] = etc_classifier\n",
    "    etc_predictions[class_name] = etc_classifier.predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle the models\n",
    "# Save Model as a pickle Using joblib\n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(etc_models, 'etc_models.p') \n",
    "  \n",
    "# Load the model from the file \n",
    "pickled_models = joblib.load('etc_models.p')  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_models['toxic'].fit(train_features, train_target)\n",
    "predictions['toxic'] = pickled_models['toxic'].predict_proba(test_features)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Code (Unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _train_model(train_x, test_features):\n",
    "#     predictions = {'id': test['id']}\n",
    "#     for class_name in class_names:\n",
    "#         train_target = train[class_name]\n",
    "#         classifier = LogisticRegression(solver='sag')\n",
    "#         classifier.fit(train_X, train_y)\n",
    "#         predictions[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "#     return predictions\n",
    "\n",
    "# def train_folds(X, y, fold_count, test_features):\n",
    "#     fold_size = len(X) // fold_count\n",
    "#     all_predections = []\n",
    "#     for fold_id in range(0, fold_count):\n",
    "#         fold_start = fold_size * fold_id\n",
    "#         fold_end = fold_start + fold_size\n",
    "\n",
    "#         if fold_id == fold_size - 1:\n",
    "#             fold_end = len(X)\n",
    "\n",
    "#         train_x = np.concatenate([X[:fold_start], X[fold_end:]])\n",
    "#         train_y = np.concatenate([y[:fold_start], y[fold_end:]])\n",
    "\n",
    "#         val_x = X[fold_start:fold_end]\n",
    "#         val_y = y[fold_start:fold_end]\n",
    "    \n",
    "#         print(\"In fold #\", fold_id)\n",
    "#         all_predections.append(_train_model(train_x, train_y))\n",
    "#     return all_predections\n",
    "\n",
    "# train_folds(train_features, test_features, train_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# submission = pd.DataFrame.from_dict(predictions)\n",
    "# submission.to_csv('Logistic-Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup nltk corpora path and Google Word2Vec location\n",
    "google_vec_file = '/Users/randy/Documents/GitHub/Twitch_Chat_Harassment/notebooks/GoogleNews-vectors-negative300.bin.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar('king' ,topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.n_similarity(['king', 'man'], ['queen', 'woman'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
